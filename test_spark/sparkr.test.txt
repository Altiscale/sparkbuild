df <- createDataFrame(sqlContext, faithful) 
head(df)

people <- read.df(sqlContext, "spark/test/sparkr/people.json", "json")
head(people)
printSchema(people)

write.df(people, path="spark/test/sparkr/people.parquet", source="parquet", mode="overwrite")

results <- sql(hiveContext, "FROM spark_hive_test_yarn_cluster_table SELECT key, value")
head(results)

df <- createDataFrame(sqlContext, faithful) 
df
head(select(df, df$eruptions))
head(select(df, "eruptions"))
head(filter(df, df$waiting < 50))

head(summarize(groupBy(df, df$waiting), count = n(df$waiting)))

waiting_counts <- summarize(groupBy(df, df$waiting), count = n(df$waiting))
head(arrange(waiting_counts, desc(waiting_counts$count)))

df$waiting_secs <- df$waiting * 60
head(df)

people <- read.df(sqlContext, "spark/test/sparkr/people.json", "json")
registerTempTable(people, "people")
teenagers <- sql(sqlContext, "SELECT name FROM people WHERE age >= 13 AND age <= 19")
head(teenagers)


